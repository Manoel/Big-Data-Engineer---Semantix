[![](https://github.com/Manoel/Big-Data-Engineer-Semantix/blob/main/logo.png)](https://www.linkedin.com/in/manoel-rodrigues-do-nascimento-2359a732)

[![](https://img.shields.io/badge/made%20by-manoel-blue)](https://www.linkedin.com/in/manoel-rodrigues-do-nascimento-2359a732)

</br></br>
`Duração:` 2 meses, 110 horas
</br></br>
bootcamp: [https://semantix.gupy.io/jobs/1438759](https://semantix.gupy.io/jobs/1438759)
</br></br>

No programa de formação da [Semantix Academy](https://semantix.ai/academy/) você irá aprender os conceitos Big Data, e durante o treinamento você passará por alguns desafios para auxiliar em sua avaliação, habilitando o aluno para atuar profissionalmente na área.</br>
Assim possibiliou que pudesse estudar através de desafios semanais sucessivos que evoluem em complexidade e abrangência.

## Conteúdo do bootcamp

Nos links abaixo de cada módulo disponibilizo materiais de trabalhos práticos e desafios estudados no bootcamp:
| [MÓDULO_1](https://github.com/Manoel/Big-Data-Engineer-Semantix/tree/main/Modulo_Big_Data_Foundations) | [MÓDULO_2](https://github.com/Manoel/Big-Data-Engineer-Semantix/tree/main/Modulo_MongoDB) | [MÓDULO_3](https://github.com/Manoel/Big-Data-Engineer-Semantix/tree/main/Modulo_Redis) | [MÓDULO_4](https://github.com/Manoel/Big-Data-Engineer-Semantix/tree/main/Modulo_Kafka) | [MÓDULO_5](https://github.com/Manoel/Big-Data-Engineer-Semantix/tree/main/Modulo_Elastic) | [MÓDULO_6](https://github.com/Manoel/Big-Data-Engineer-Semantix/tree/main/Modulo_Spark) |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Semana 1 e 2                                                 | Semana 3                                                     | Semana 4                                                     | Semana 5                                                     | Semana 6 e 7                                                 | Semana 8, 9 e 10                                             |
| Big Data Foundations                                         | MongoDB                                                      | Redis                                                        | Apache Kafka                                                 | Elastic Essential I                                          | Spark - Big Data Processing                                  |
| • Conhecimento de ferramentas atuais no mercado de Big Data;<br/><br/>• Criação e funcionamento de um cluster Hadoop para Big Data em Docker;<br/><br/>• Manipulação de dados com HDFS;  <br/>• Manipulação de dados com uso do Hive;<br/>• Otimização de consultas em grandes volumes de dados estruturados e semiestruturados com uso de Hive;<br/>• Ingestão de dados relacionais para o HDFS/Hive, com uso do Sqoop;<br/><br/>• Otimização de importação no Sqoop;<br/>• Exportação de dados do HDFS para o SGBD, com uso do Sqoop;<br/><br/>• Manipulação de dados com HBase;<br/>• Operações com Dataframe em Spark para processamento de dados em batch;<br/>• Uso do Spark SQL Queries para consultas de dados estruturados e semiestruturados. | • Entendimento de conceitos e arquitetura NoSQL e MongoDB;<br/><br/>• Instalação de cluster MongoDB através de container e Cloud;<br/><br/>• Manipular coleções, documentos e índices;<br/><br/>• Realizar diversas pesquisas no MongoDB com diferentes operadores;<br/><br/>• Fazer uso das interfaces gráficas MongoExpress e MongoCompass;<br/><br/>• Trabalhar com pipeline de agregações;<br/><br/>• Entendimento de Replicação e shards. | • Entendimento de conceitos e arquitetura NoSQL e Redis;<br/><br/>• Instalação de cluster Redis através de container;<br/><br/>• Manipulação de diversos tipos de estrutura de dados com Redis-CLI;<br/><br/>• Implementar paradigma de mensagens Pub/Sub;<br/><br/>• Configurações básicas de persistência de dados. | • Entendimento de conceitos e arquitetura do Kafka e da Confluent;<br/><br/>• Instalação de cluster Kafka através de container;<br/><br/>• Gerenciamento de tópicos;<br/><br/>• Produção e consumo de dados através do console;<br/><br/>• Entendimento das guias do Control Center;<br/><br/>• Desenvolvimento de stream com uso do KSQL;<br/><br/>• Aplicação de KSQL Datagen;<br/><br/>• Produção e consumo de dados com uso do Schema Registry;<br/><br/>• Trabalhando com Kafka Connect;<br/><br/>• Custos com Confluent Cloud;<br/><br/>• Otimização de parâmetros;<br/><br/>• Melhores práticas em um cluster Kafka. | • Entendimento de conceitos e arquitetura da Elastic;<br/><br/>• Instalação de cluster Elastic através de container;<br/><br/>• Realizar operações de CRUD em índices;<br/><br/>• Gerenciamento de índices;<br/><br/>• Alteração de mapeamento e reindex;<br/><br/>• Desenvolvimento de consultas do tipo term, terms, range, match e multi_match, com uso de bool query;<br/><br/>• Aplicação de analyzers em atributos;<br/><br/>• Desenvolvimento de agregações básicas;<br/><br/>• Ingestão de dados através de beats e logstash;<br/><br/>• Entendimento das guias do Kibana; | • Uso do Jupyter Notebooks para a criação de projetos em Spark com Python<br/><br/>• Spark batch intermediario<br/><br/>• Operações com RDD em Spark para processamento de dados em batch;<br/><br/>• Uso de Partições com RDD;<br/><br/>• Operações com Dataset em Spark para processamento de dados em batch;<br/><br/>• Uso de Dataset em Dataframe e RDD;<br/><br/>• Comandos avançados com Dataset;<br/><br/>• Uso do IntelliJ IDEA para a criação de projetos em Spark com Scala;<br/><br/>• Struct Streaming para leitura de dados do Kafka;<br/><br/>• Spark Streaming para leitura de dados do Kafka;<br/><br/>• Otimizações com uso de Variáveis Compartilhadas;<br/><br/>• Criações de User defined Function;<br/><br/>• Configurações de Tunning para o Spark Application. |



